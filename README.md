# README - Executando Apache Spark no Google Colab

Este é um guia passo a passo para configurar e executar o Apache Spark no ambiente do Google Colab usando Python.

## Pré-requisitos
Antes de começar, você precisará de:

- Uma conta no Google para acessar o Google Colab.
- Conhecimento básico de Python e manipulação de notebooks.

## Executando o Código
Para executar o código, abra o Google Colab e crie um novo notebook Python. Em seguida, copie e cole o código acima no notebook. Certifique-se de executar as células do notebook sequencialmente.

## Verificando a Instalação
Após a execução do código, o Apache Spark estará configurado e pronto para uso no ambiente do Google Colab. A variável `sc` contém a sessão do Spark criada com sucesso.

## Uso do Apache Spark
A partir da sessão do Spark criada, você pode utilizar as funcionalidades do Spark, como manipulação de dados com a API DataFrame, machine learning, análise de dados em larga escala e muito mais.

## Conclusão
Com a configuração do Apache Spark no Google Colab, você pode aproveitar todo o poder do Spark para processar e analisar grandes volumes de dados de forma eficiente e escalável.

Espero que este guia seja útil para você começar a trabalhar com o Apache Spark no Google Colab. Se tiver alguma dúvida ou quiser saber mais sobre o Spark ou outras ferramentas de ciência de dados, fique à vontade para perguntar!
